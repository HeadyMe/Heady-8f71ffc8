# ðŸ¤” Heady HeadyBattle Method Configuration
# Critical interrogation for every system decision

id: HeadyBattle-interrogator
name: HeadyHeadyBattle
version: 3.0.0
type: governance
owner: core

enabled: true
interrogation_depth: 3
validation_required: true
critical_mode: true

question_categories:
  purpose:
    weight: 0.30
    questions:
      - id: "primary_goal"
        text: "What is the primary purpose of this change?"
        critical: true
        follow_up: ["How does this serve Heady's mission?", "What problem does this solve?"]
        
      - id: "mission_alignment"
        text: "How does this align with Sacred Geometry principles?"
        critical: true
        follow_up: ["Does this maximize global happiness?", "Is this fair wealth redistribution?"]
        
      - id: "user_impact"
        text: "Who benefits from this change?"
        critical: true
        follow_up: ["Are there unintended consequences?", "Is this inclusive?"]

  consequences:
    weight: 0.25
    questions:
      - id: "risk_analysis"
        text: "What could go wrong with this approach?"
        critical: true
        follow_up: ["What are the failure modes?", "How do we mitigate risks?"]
        
      - id: "system_impact"
        text: "How does this affect other system components?"
        critical: true
        follow_up: ["Are there coupling issues?", "What breaks if this fails?"]
        
      - id: "resource_implications"
        text: "What resources does this consume?"
        critical: false
        follow_up: ["Is this sustainable?", "Are there opportunity costs?"]

  optimization:
    weight: 0.25
    questions:
      - id: "elegance_check"
        text: "Is this the most elegant solution?"
        critical: true
        follow_up: ["Can this be simplified?", "Is there unnecessary complexity?"]
        
      - id: "pattern_consistency"
        text: "What patterns does this establish or break?"
        critical: true
        follow_up: ["Is this consistent with existing patterns?", "Should this be a new pattern?"]
        
      - id: "future_proofing"
        text: "How will this age over time?"
        critical: false
        follow_up: ["Is this maintainable?", "What are the technical debt implications?"]

  ethics:
    weight: 0.20
    questions:
      - id: "ethical_implications"
        text: "Are there ethical considerations?"
        critical: true
        follow_up: ["Does this respect user privacy?", "Is this transparent?"]
        
      - id: "accessibility"
        text: "Is this accessible to all users?"
        critical: true
        follow_up: ["What about users with disabilities?", "Is this inclusive by design?"]

validation_rules:
  minimum_score: 0.80
  critical_questions_required: true
  human_review_threshold: 0.70
  
  scoring:
    excellent: 0.90-1.0
    good: 0.80-0.89
    acceptable: 0.70-0.79
    needs_improvement: 0.60-0.69
    reject: < 0.60

interrogation_process:
  1. initial_analysis:
     - auto_detect_changes
     - categorize_change_type
     - select_relevant_questions
     
  2. question_application:
     - apply_category_questions
     - generate_follow_up_questions
     - collect_responses
     
  3. scoring_evaluation:
     - calculate_category_scores
     - apply_weighted_averaging
     - determine_final_score
     
  4. validation_decision:
     - check_minimum_threshold
     - flag_critical_issues
     - recommend_approval/rejection

automation_rules:
  auto_approve:
    conditions:
      - score >= 0.90
      - no_critical_issues
      - pattern_consistency_pass
      
  human_review_required:
    conditions:
      - score between 0.70-0.89
      - ethical_implications_detected
      - system_wide_impact
      
  auto_reject:
    conditions:
      - score < 0.60
      - critical_questions_unanswered
      - ethical_violations_detected

integration_points:
  monte_carlo:
    - validate_strategies_before_simulation
    - score_simulation_results
    - interrogate_promotion_decisions
    
  arena_mode:
    - interrogate_candidate_strategies
    - validate_promotion_criteria
    - score_arena_outcomes
    
  branch_automation:
    - interrogate_development_changes
    - validate_staging_promotions
    - approve_main_merges

monitoring:
  effectiveness_tracking:
    - question_impact_scores
    - validation_accuracy
    - false_positive_rate
    - false_negative_rate
    
  quality_metrics:
    - interrogation_coverage
    - response_quality
    - decision_consistency
    - learning_integration

api:
  base_path: /api/HeadyBattle
  endpoints:
    - GET /questions
    - POST /interrogate
    - POST /validate
    - GET /results
    - POST /score

environment_variables:
  SOCRATIC_ENABLED: true
  INTERROGATION_DEPTH: 3
  MINIMUM_SCORE: 0.80
  CRITICAL_MODE: true
  HUMAN_REVIEW_THRESHOLD: 0.70

learning_integration:
  enabled: true
  question_optimization: true
  pattern_learning: true
  effectiveness_tracking: true
  
  adaptation_rules:
    - improve_low_impact_questions
    - add_missing_critical_questions
    - adjust_category_weights
    - optimize_follow_up_logic
